{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/caffeine.png\" alt=\"drawing\" width=\"500\" align=\"left\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a graph \n",
    "\n",
    "* You need to define node features and Edge features for the graph \n",
    "\n",
    "* The node features has shape of: ~ (N, node_features)\n",
    "\n",
    "* And the edge features dictionary has shape of: ~ (N, N, edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usally we create this for all the molecules  in the problem (here we are showing for one molecule)\n",
    "# So we need to update the ATOM_TYPE and BOND_TYPE lists based on the all elements and all type of bonds we are going to work on \n",
    "# also here we are considering one node feature (atom) and one edge feature (bond type), but in general we have more than one\n",
    "\n",
    "ATOM_TYPES = {'C': 0, 'N': 1, 'O': 2} # nodes encoding \n",
    "BOND_TYPES = {'S': 0, 'D': 1, 'A': 2} # edges encoding \n",
    "\n",
    "# caffeine nodes \n",
    "sym_caffeine_nodes = {1: {'atom_type': 'C'},\n",
    "                    2: {'atom_type': 'N'},\n",
    "                    3: {'atom_type': 'C'},\n",
    "                    4: {'atom_type': 'O'},\n",
    "                    5: {'atom_type': 'C'},\n",
    "                    6: {'atom_type': 'N'},\n",
    "                    7: {'atom_type': 'C'},\n",
    "                    8: {'atom_type': 'C'},\n",
    "                    9: {'atom_type': 'N'},\n",
    "                    10: {'atom_type': 'C'},\n",
    "                    11: {'atom_type': 'N'},\n",
    "                    12: {'atom_type': 'C'},\n",
    "                    13: {'atom_type': 'C'},\n",
    "                    14: {'atom_type': 'O'}}\n",
    "\n",
    "# caffeine edges \n",
    "sym_caffeine_edges = {frozenset({1,2}): {'bond_type': 'S'},\n",
    "                    frozenset({2,3}): {'bond_type': 'S'},\n",
    "                    frozenset({2,13}): {'bond_type': 'S'},\n",
    "                    frozenset({3,4}): {'bond_type': 'D'},\n",
    "                    frozenset({3,5}): {'bond_type': 'S'},\n",
    "                    frozenset({5,6}): {'bond_type': 'A'},\n",
    "                    frozenset({5,10}): {'bond_type': 'A'},\n",
    "                    frozenset({6,7}): {'bond_type': 'S'},\n",
    "                    frozenset({6,8}): {'bond_type': 'A'},\n",
    "                    frozenset({8,9}): {'bond_type': 'A'},\n",
    "                    frozenset({9,10}): {'bond_type': 'A'},\n",
    "                    frozenset({10,11}): {'bond_type': 'S'},\n",
    "                    frozenset({11,12}): {'bond_type': 'S'},\n",
    "                    frozenset({11,13}): {'bond_type': 'S'},\n",
    "                    frozenset({13,14}): {'bond_type': 'D'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node features \n",
    "\n",
    "1. We need to first encode the categorical node features into integers \n",
    "2. Then we need to create embeddings for (each) encoded integers\n",
    "3. Finally the numerical node features will be stacked to have shape of: (N, node_feat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'atom_type': 0},\n",
       " 2: {'atom_type': 1},\n",
       " 3: {'atom_type': 0},\n",
       " 4: {'atom_type': 2},\n",
       " 5: {'atom_type': 0},\n",
       " 6: {'atom_type': 1},\n",
       " 7: {'atom_type': 0},\n",
       " 8: {'atom_type': 0},\n",
       " 9: {'atom_type': 1},\n",
       " 10: {'atom_type': 0},\n",
       " 11: {'atom_type': 1},\n",
       " 12: {'atom_type': 0},\n",
       " 13: {'atom_type': 0},\n",
       " 14: {'atom_type': 2}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode node attributes \n",
    "enc_caffeine_nodes = {}\n",
    "for node_idx, node_attributes in sym_caffeine_nodes.items():\n",
    "    sym_atom_type = node_attributes['atom_type']\n",
    "    encoded_atom_type = ATOM_TYPES[sym_atom_type]\n",
    "    enc_caffeine_nodes[node_idx] = {'atom_type': encoded_atom_type}\n",
    "\n",
    "enc_caffeine_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1, 2}): {'bond_type': 0},\n",
       " frozenset({2, 3}): {'bond_type': 0},\n",
       " frozenset({2, 13}): {'bond_type': 0},\n",
       " frozenset({3, 4}): {'bond_type': 1},\n",
       " frozenset({3, 5}): {'bond_type': 0},\n",
       " frozenset({5, 6}): {'bond_type': 2},\n",
       " frozenset({5, 10}): {'bond_type': 2},\n",
       " frozenset({6, 7}): {'bond_type': 0},\n",
       " frozenset({6, 8}): {'bond_type': 2},\n",
       " frozenset({8, 9}): {'bond_type': 2},\n",
       " frozenset({9, 10}): {'bond_type': 2},\n",
       " frozenset({10, 11}): {'bond_type': 0},\n",
       " frozenset({11, 12}): {'bond_type': 0},\n",
       " frozenset({11, 13}): {'bond_type': 0},\n",
       " frozenset({13, 14}): {'bond_type': 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode edge attributes \n",
    "enc_caffeine_edges = {}\n",
    "for edge, edge_attributes in sym_caffeine_edges.items():\n",
    "    sym_bond_type = edge_attributes['bond_type']\n",
    "    encoded_bond_type = BOND_TYPES[sym_bond_type]\n",
    "    enc_caffeine_edges[edge] = {'bond_type': encoded_bond_type}\n",
    "    \n",
    "enc_caffeine_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "          1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "        [ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
       "         -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411],\n",
       "        [-0.7672, -1.8820, -1.9126,  0.9441,  0.8713,  0.2552, -0.7308, -0.5687,\n",
       "         -1.7632, -0.4655, -0.0700, -0.5780, -1.9135,  0.4369, -0.0833,  0.5947]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node embeddings (for catergorical data)\n",
    "num_embeddings = len(ATOM_TYPES)\n",
    "embedding_dim = 16  # This is a hyper parameter\n",
    "\n",
    "# one embedding vector for one atom type (i.e. if the atom is same, then the embedding vector will be same )\n",
    "ATOM_TYPE_EMBEDDINGS = torch.randn((num_embeddings, embedding_dim))\n",
    "ATOM_TYPE_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'atom_type': tensor([ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
      "         1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614])}\n",
      "2 {'atom_type': tensor([ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
      "        -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411])}\n",
      "3 {'atom_type': tensor([ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
      "         1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614])}\n"
     ]
    }
   ],
   "source": [
    "# embedded caffeine nodes \n",
    "embedded_caffeine_nodes = {}\n",
    "for node_idx, encoded_node_features in enc_caffeine_nodes.items():\n",
    "    encoded_atom_type = encoded_node_features['atom_type']\n",
    "    embedded_atom_type = ATOM_TYPE_EMBEDDINGS[encoded_atom_type]  \n",
    "    embedded_node_features = {'atom_type': embedded_atom_type}\n",
    "    embedded_caffeine_nodes[node_idx] = embedded_node_features\n",
    "\n",
    "# print first 3 \n",
    "i=0\n",
    "for idx,embedded_node_feats in embedded_caffeine_nodes.items():\n",
    "    if i<3:\n",
    "        print(idx,embedded_node_feats)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to create tensors (here we are stacking node fatures for each node)\n",
    "# Please read slide #1 in the GNN powerpoint \n",
    "caffeine_node_features_stack = dict()\n",
    "for node_idx,embedded_features in sorted(embedded_caffeine_nodes.items()):\n",
    "    for varibale_name, embedding in embedded_features.items():\n",
    "        if varibale_name not in caffeine_node_features_stack:\n",
    "            caffeine_node_features_stack[varibale_name] = []\n",
    "        caffeine_node_features_stack[varibale_name].append(embedding)\n",
    "        \n",
    "stacked_node_features = dict()\n",
    "for variable_name,stack in caffeine_node_features_stack.items():\n",
    "    feature_tensor = torch.stack(stack)\n",
    "    stacked_node_features[variable_name] = feature_tensor\n",
    "\n",
    "stacked_node_features['atom_type'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_type': [0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's combine the steps involving encoding and embedding (seperatly)\n",
    "\n",
    "# STEP 1: ENCODING \n",
    "enc_caffeine_nodes_stack = {'atom_type': []}\n",
    "for node_idx, node_attributes in sym_caffeine_nodes.items():\n",
    "    sym_atom_type = node_attributes['atom_type']\n",
    "    encoded_atom_type = ATOM_TYPES[sym_atom_type]\n",
    "    enc_caffeine_nodes_stack['atom_type'].append(encoded_atom_type)\n",
    "enc_caffeine_nodes_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_type': tensor([[ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
       "          -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [-0.7672, -1.8820, -1.9126,  0.9441,  0.8713,  0.2552, -0.7308, -0.5687,\n",
       "          -1.7632, -0.4655, -0.0700, -0.5780, -1.9135,  0.4369, -0.0833,  0.5947],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
       "          -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
       "          -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.8430, -0.3465,  0.5837,  1.3363, -0.6648, -0.5628,  1.2693, -1.4810,\n",
       "          -1.0072,  0.8442,  0.1683, -0.4431,  1.2046,  1.9453,  1.3180, -0.3411],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
       "           1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614],\n",
       "         [-0.7672, -1.8820, -1.9126,  0.9441,  0.8713,  0.2552, -0.7308, -0.5687,\n",
       "          -1.7632, -0.4655, -0.0700, -0.5780, -1.9135,  0.4369, -0.0833,  0.5947]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP2: EMBEDDING \n",
    "emb_caffeine_nodes_stack = {}\n",
    "for variable_name, encoded_stack in enc_caffeine_nodes_stack.items():\n",
    "    enc_tensor = torch.tensor(encoded_stack, dtype=torch.long)\n",
    "    emb_tensor = ATOM_TYPE_EMBEDDINGS[enc_tensor] \n",
    "    emb_caffeine_nodes_stack[variable_name] = emb_tensor\n",
    "emb_caffeine_nodes_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0578, -0.2147, -0.4536,  0.0059,  0.4652,  0.4706,  0.2161,  0.7681,\n",
       "          0.1815,  0.5205,  0.5546,  0.1349,  0.8154,  1.2754,  0.2409,  0.7473],\n",
       "        [-0.5989,  0.1858, -1.6824,  0.9686, -1.0566, -0.8747, -0.3959, -1.4704,\n",
       "         -0.5375,  0.1018, -1.3207,  0.3371,  0.1343,  0.7643,  1.1319, -0.2975],\n",
       "        [ 0.1107,  0.1844,  0.2405,  0.2023, -0.6089, -0.1008, -0.4015, -0.2590,\n",
       "         -1.0013,  0.4503,  0.0435,  1.4452,  0.5089, -1.1479,  0.3041, -1.1514]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bond type embedding \n",
    "num_embeddings = len(BOND_TYPES)\n",
    "embedding_dim = 16  # This is a hyper parameter, you can set it to whatever value you like (though 1 will work poorly)\n",
    "BOND_TYPE_EMBEDDINGS = torch.randn((num_embeddings, embedding_dim))\n",
    "BOND_TYPE_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emplty (filled with zeros) caffine edge feature tensor \n",
    "caffeine_nodes = sym_caffeine_nodes.keys()\n",
    "n_nodes = len(caffeine_nodes)\n",
    "caffeine_nodes_indices = {node_idx: i for i, node_idx in enumerate(sorted(caffeine_nodes))} # to get indx -> int \n",
    "caffeine_edge_features_tensor = torch.zeros((n_nodes, n_nodes, embedding_dim), dtype=BOND_TYPE_EMBEDDINGS.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({1, 2}) {'bond_type': tensor([ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
      "         1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614])}\n",
      "frozenset({2, 3}) {'bond_type': tensor([ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
      "         1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614])}\n",
      "frozenset({2, 13}) {'bond_type': tensor([ 0.5915,  0.2338, -0.5236, -0.5252, -0.2997, -0.2778, -0.8636,  2.6273,\n",
      "         1.1535, -1.4986,  1.0591,  1.6145,  0.7571, -0.2929,  0.4991,  0.0614])}\n"
     ]
    }
   ],
   "source": [
    "# embedded caffeine edges \n",
    "embedded_caffeine_edges = {}\n",
    "\n",
    "for edge_idx, encoded_edge_features in enc_caffeine_edges.items():\n",
    "    encoded_bond_type = encoded_edge_features['bond_type']\n",
    "    embedded_bond_type = ATOM_TYPE_EMBEDDINGS[encoded_bond_type]\n",
    "    embedded_bond_features = {'bond_type':embedded_bond_type}\n",
    "    embedded_caffeine_edges[edge_idx] = embedded_bond_features\n",
    "    \n",
    "# print first 3  \n",
    "i=0\n",
    "for idx,embedded_edge_feats in embedded_caffeine_edges.items():\n",
    "    if i<3:\n",
    "        print(idx,embedded_edge_feats)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (node_u,node_v),features in embedded_caffeine_edges.items():\n",
    "    node_u_idx = caffeine_nodes_indices[node_u]\n",
    "    node_v_idx = caffeine_nodes_indices[node_v]\n",
    "    caffeine_edge_features_tensor[node_u_idx,node_v_idx] = features['bond_type']\n",
    "    \n",
    "# has shape of : (N,N,d_edge_feat)\n",
    "caffeine_edge_features_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Categorical and continuos  variable class \n",
    "\n",
    "* This makes easy to handle categorical data and continuous data effectively \n",
    "* For example if we want to define the \"NULL\" category this makes it easier, we don't need to handle it separately every time when we define categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for continous data \n",
    "class ContinuousVariable:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f''\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for categorical data \n",
    "\n",
    "class CategoricalVariable:\n",
    "    def __init__(self, name, values, add_null_value=True):\n",
    "        self.name = name\n",
    "        self.has_null_value = add_null_value\n",
    "        if self.has_null_value:\n",
    "            self.null_value = None\n",
    "            values = (None,) + tuple(values)\n",
    "        self.values = tuple(values)\n",
    "        self.value_to_idx_mapping = {v: i for i, v in enumerate(values)}\n",
    "        self.inv_value_to_idx_mapping = {i: v for v, i in\n",
    "                                            self.value_to_idx_mapping.items()}\n",
    "\n",
    "        if self.has_null_value:\n",
    "            self.null_value_idx = self.value_to_idx_mapping[self.null_value]\n",
    "\n",
    "    def get_null_idx(self):\n",
    "        if self.has_null_value:\n",
    "            return self.null_value_idx\n",
    "        else:\n",
    "            raise RuntimeError(f\"Categorical variable {self.name} has no null value\")\n",
    "\n",
    "    def value_to_idx(self, value):\n",
    "        return self.value_to_idx_mapping[value]\n",
    "\n",
    "    def idx_to_value(self, idx):\n",
    "        return self.inv_value_to_idx_mapping[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f''\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.values == other.values\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding multiple node and edge attributes\n",
    "\n",
    "* So far we encoded one node feature (atom type) and one edge feature (bond type)\n",
    "\n",
    "* Let's try to generalize this for multiple node features (ex. 'atom_type', 'is_aromatic', 'num_hydrogen' and etc) and multiple edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node features (here we have 4 features)\n",
    "ATOM_TYPE_VARIABLE = CategoricalVariable('atom_type', ['C', 'N', 'O'])\n",
    "ATOM_IS_AROMATIC_VARIABLE = CategoricalVariable('is_aromatic', [True, False])\n",
    "ATOM_HYDROGENS_VARIABLE = ContinuousVariable('num_hydrogens')\n",
    "ATOM_VARIABLES = [ATOM_TYPE_VARIABLE, ATOM_IS_AROMATIC_VARIABLE, ATOM_HYDROGENS_VARIABLE]\n",
    "\n",
    "# let's put node features in the node dictionary \n",
    "caffeine_nodes = {1: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                2: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                3: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                4: {ATOM_TYPE_VARIABLE: 'O', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                5: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                6: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                7: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                8: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 1},\n",
    "                9: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                10: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                11: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                12: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                13: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                14: {ATOM_TYPE_VARIABLE: 'O', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0}}\n",
    "\n",
    "# edge features (we have 3 here)\n",
    "BOND_TYPES_VARIABLE = CategoricalVariable('bond_type', ('S', 'D', 'A'))\n",
    "BOND_IS_AROMATIC_VARIABLE = CategoricalVariable('is_aromatic', (True, False))\n",
    "BOND_VARIABLES = [BOND_TYPES_VARIABLE, BOND_IS_AROMATIC_VARIABLE]\n",
    "\n",
    "# let's put the edge features in feature dictionary \n",
    "caffeine_edges = {frozenset({1,2}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({2,3}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({2,13}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({3,4}): {BOND_TYPES_VARIABLE: 'D', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({3,5}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({5,6}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({5,10}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({6,7}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({6,8}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({8,9}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({9,10}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({10,11}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({11,12}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({11,13}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({13,14}): {BOND_TYPES_VARIABLE: 'D', BOND_IS_AROMATIC_VARIABLE: False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
