{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections.abc import Set\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Sequential,Linear,ReLU, Module, Embedding, ModuleList, LayerNorm, Dropout\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "float_type = torch.float32  \n",
    "categorical_type = torch.long\n",
    "mask_type = torch.float32  \n",
    "labels_type = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to handle cts variables \n",
    "class ContinuousVariable:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<ContinuousVariable: {self.name}>'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "    \n",
    "# class to handle cat variables \n",
    "class CategoricalVariable:\n",
    "    def __init__(self, name, values, add_null_value=True):\n",
    "        self.name = name\n",
    "        self.has_null_value = add_null_value\n",
    "        if self.has_null_value:\n",
    "            self.null_value = None\n",
    "            values = (None,) + tuple(values)\n",
    "        self.values = tuple(values)\n",
    "        self.value_to_idx_mapping = {v: i for i, v in enumerate(values)}\n",
    "        self.inv_value_to_idx_mapping = {i: v for v, i in self.value_to_idx_mapping.items()}\n",
    "\n",
    "        if self.has_null_value:\n",
    "            self.null_value_idx = self.value_to_idx_mapping[self.null_value]\n",
    "\n",
    "    def get_null_idx(self):\n",
    "        if self.has_null_value:\n",
    "            return self.null_value_idx\n",
    "        else:\n",
    "            raise RuntimeError(f\"Categorical variable {self.name} has no null value\")\n",
    "\n",
    "    def value_to_idx(self, value):\n",
    "        return self.value_to_idx_mapping[value]\n",
    "\n",
    "    def idx_to_value(self, idx):\n",
    "        return self.inv_value_to_idx_mapping[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<CategoricalVariable: {self.name}>'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.values == other.values\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dataset class: this returns graph attributes for set of graphs  \n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, *, graphs, labels, node_variables, edge_variables, metadata=None):\n",
    "        '''\n",
    "        Create a new graph dataset, \n",
    "        '''\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "        assert len(self.graphs) == len(self.labels), \"The graphs and labels lists must be the same length\"\n",
    "        self.metadata = metadata\n",
    "        if self.metadata is not None:\n",
    "            assert len(self.metadata) == len(self.graphs), \"The metadata list needs to be as long as the graphs\"\n",
    "        self.node_variables = node_variables\n",
    "        self.edge_variables = edge_variables\n",
    "        self.categorical_node_variables = [var for var in self.node_variables if isinstance(var, CategoricalVariable)]\n",
    "        self.continuous_node_variables = [var for var in self.node_variables if isinstance(var, ContinuousVariable)]\n",
    "        self.categorical_edge_variables = [var for var in self.edge_variables if isinstance(var, CategoricalVariable)]\n",
    "        self.continuous_edge_variables = [var for var in self.edge_variables if isinstance(var, ContinuousVariable)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def make_continuous_node_features(self, nodes):\n",
    "        if len(self.continuous_node_variables) == 0:\n",
    "            return None\n",
    "        n_nodes = len(nodes)\n",
    "        n_features = len(self.continuous_node_variables)\n",
    "        continuous_node_features = torch.zeros((n_nodes, n_features), dtype=float_type)\n",
    "        for node_idx, features in nodes.items():\n",
    "            node_features = torch.tensor([features[continuous_feature] for continuous_feature in self.continuous_node_variables], dtype=float_type)\n",
    "            continuous_node_features[node_idx] = node_features\n",
    "        return continuous_node_features\n",
    "    \n",
    "    def make_categorical_node_features(self, nodes):\n",
    "        if len(self.categorical_node_variables) == 0:\n",
    "            return None\n",
    "        n_nodes = len(nodes)\n",
    "        n_features = len(self.categorical_node_variables)\n",
    "        categorical_node_features = torch.zeros((n_nodes, n_features), dtype=categorical_type)\n",
    "\n",
    "        for node_idx, features in nodes.items():\n",
    "            for i, categorical_variable in enumerate(self.categorical_node_variables):\n",
    "                value = features[categorical_variable]\n",
    "                value_index = categorical_variable.value_to_idx(value)\n",
    "                categorical_node_features[node_idx, i] = value_index\n",
    "        return categorical_node_features\n",
    "\n",
    "    def make_continuous_edge_features(self, n_nodes, edges):\n",
    "        if len(self.continuous_edge_variables) == 0:\n",
    "            return None\n",
    "        n_features = len(self.continuous_edge_variables)\n",
    "        continuous_edge_features = torch.zeros((n_nodes, n_nodes, n_features), dtype=float_type)\n",
    "        for edge, features in edges.items():\n",
    "            edge_features = torch.tensor([features[continuous_feature] for continuous_feature in self.continuous_edge_variables], dtype=float_type)\n",
    "            u,v = edge\n",
    "            continuous_edge_features[u, v] = edge_features\n",
    "            if isinstance(edge, Set):\n",
    "                continuous_edge_features[v, u] = edge_features\n",
    "        return continuous_edge_features\n",
    "\n",
    "    def make_categorical_edge_features(self, n_nodes, edges):\n",
    "        if len(self.categorical_edge_variables) == 0:\n",
    "            return None\n",
    "        n_features = len(self.categorical_edge_variables)\n",
    "        categorical_edge_features = torch.zeros((n_nodes, n_nodes, n_features), dtype=categorical_type)\n",
    "\n",
    "        for edge, features in edges.items():\n",
    "            u,v = edge\n",
    "            for i, categorical_variable in enumerate(self.categorical_edge_variables):\n",
    "                value = features[categorical_variable]\n",
    "                value_index = categorical_variable.value_to_idx(value)\n",
    "                categorical_edge_features[u, v, i] = value_index\n",
    "                if isinstance(edge, Set):\n",
    "                    categorical_edge_features[v, u, i] = value_index\n",
    "        return categorical_edge_features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        graph = self.graphs[index]\n",
    "        nodes, edges = graph\n",
    "        n_nodes = len(nodes)\n",
    "        continuous_node_features = self.make_continuous_node_features(nodes)\n",
    "        categorical_node_features = self.make_categorical_node_features(nodes)\n",
    "        continuous_edge_features = self.make_continuous_edge_features(n_nodes, edges)\n",
    "        categorical_edge_features = self.make_categorical_edge_features(n_nodes, edges)\n",
    "\n",
    "        label = self.labels[index]\n",
    "        nodes_idx = sorted(nodes.keys())\n",
    "        edge_list = sorted(edges.keys())\n",
    "        n_nodes = len(nodes)\n",
    "        adjacency_matrix = torch.zeros((n_nodes, n_nodes), dtype=float_type)\n",
    "        \n",
    "        for edge in edges:\n",
    "            u, v = edge\n",
    "            adjacency_matrix[u,v] = 1\n",
    "            if isinstance(edge, Set):\n",
    "                # This edge is unordered, assume this is a undirected graph\n",
    "                adjacency_matrix[v,u] = 1\n",
    "\n",
    "        adjacency_list = defaultdict(list)\n",
    "        \n",
    "        for edge in edges:\n",
    "            u,v = edge\n",
    "            adjacency_list[u].append(v)\n",
    "            # Assume undirected graph is the edge is a set\n",
    "            if isinstance(edge, Set):\n",
    "                adjacency_list[v].append(u)\n",
    "\n",
    "        data_record = {'nodes': nodes_idx,\n",
    "                    'adjacency_matrix': adjacency_matrix,\n",
    "                    'adjacency_list': adjacency_list,\n",
    "                    'categorical_node_features': categorical_node_features,\n",
    "                    'continuous_node_features': continuous_node_features,\n",
    "                    'categorical_edge_features': categorical_edge_features,\n",
    "                    'continuous_edge_features': continuous_edge_features,\n",
    "                    'label': label}\n",
    "\n",
    "        if self.metadata is not None:\n",
    "            data_record['metadata'] = self.metadata[index]\n",
    "            \n",
    "        return data_record\n",
    "\n",
    "    def get_node_variables(self):\n",
    "        return {'continuous': self.continuous_node_variables,\n",
    "                'categorical': self.categorical_node_variables}\n",
    "    \n",
    "    def get_edge_variables(self):\n",
    "        return {'continuous': self.continuous_edge_variables,\n",
    "                'categorical': self.categorical_edge_variables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class handels the mini-batches of graphs \n",
    "# the graph dataset class can handle many graphs, but it can't create mini-batchs \n",
    "\n",
    "from collections.abc import Set\n",
    "\n",
    "def collate_graph_batch(batch):\n",
    "    '''Collate a batch of graph dictionaries produdce by a GraphDataset'''\n",
    "    batch_size = len(batch)\n",
    "    max_nodes = max(len(graph['nodes']) for graph in batch)\n",
    "\n",
    "    adjacency_matrices = torch.zeros((batch_size, max_nodes, max_nodes), dtype=float_type)\n",
    "    labels = torch.tensor([graph['label'] for graph in batch], dtype=labels_type)\n",
    "    stacked_continuous_node_features = None\n",
    "    stacked_categorical_node_features = None\n",
    "    stacked_continuous_edge_features = None\n",
    "    stacked_categorical_edge_features = None\n",
    "\n",
    "    nodes_mask = torch.zeros((batch_size, max_nodes), dtype=mask_type)\n",
    "    edge_mask = torch.zeros((batch_size, max_nodes, max_nodes), dtype=mask_type)\n",
    "\n",
    "    has_metadata = False\n",
    "\n",
    "    for i, graph in enumerate(batch):\n",
    "        if 'metadata' in graph:\n",
    "            has_metadata = True\n",
    "            \n",
    "        adjacency_matrix = graph['adjacency_matrix']\n",
    "        g_nodes, g_nodes = adjacency_matrix.shape\n",
    "        adjacency_matrices[i, :g_nodes, :g_nodes] = adjacency_matrix\n",
    "\n",
    "        edge_mask[i, :g_nodes, :g_nodes] = 1\n",
    "        nodes_mask[i, :g_nodes] = 1\n",
    "\n",
    "        g_continuous_node_features = graph['continuous_node_features']\n",
    "        if g_continuous_node_features is not None:\n",
    "            if stacked_continuous_node_features is None:\n",
    "                g_nodes, num_features = g_continuous_node_features.shape\n",
    "                stacked_continuous_node_features = torch.zeros((batch_size, max_nodes, num_features))\n",
    "            stacked_continuous_node_features[i, :g_nodes] = g_continuous_node_features\n",
    "\n",
    "        g_categorical_node_features = graph['categorical_node_features']\n",
    "        if g_categorical_node_features is not None:\n",
    "            if stacked_categorical_node_features is None:\n",
    "                g_nodes, num_features = g_categorical_node_features.shape\n",
    "                stacked_categorical_node_features = torch.zeros((batch_size, max_nodes, num_features), dtype=categorical_type)\n",
    "            stacked_categorical_node_features[i, :g_nodes] = g_categorical_node_features\n",
    "\n",
    "        g_continuous_edge_features = graph['continuous_edge_features']\n",
    "        if g_continuous_edge_features is not None:\n",
    "            if stacked_continuous_edge_features is None:\n",
    "                g_nodes, g_nodes, num_features = g_continuous_edge_features.shape\n",
    "                stacked_continuous_edge_features = torch.zeros((batch_size, max_nodes, max_nodes, num_features))\n",
    "            stacked_continuous_edge_features[i, :g_nodes, :g_nodes] = g_continuous_edge_features\n",
    "\n",
    "        g_categorical_edge_features = graph['categorical_edge_features']\n",
    "        if g_categorical_edge_features is not None:\n",
    "            if stacked_categorical_edge_features is None:\n",
    "                g_nodes, g_nodes, num_features = g_categorical_edge_features.shape\n",
    "                stacked_categorical_edge_features = torch.zeros((batch_size, max_nodes, max_nodes, num_features), dtype=categorical_type)\n",
    "            stacked_categorical_edge_features[i, :g_nodes, :g_nodes] = g_categorical_edge_features\n",
    "\n",
    "\n",
    "    batch_record = {'adjacency_matrices': adjacency_matrices,\n",
    "            'categorical_node_features': stacked_categorical_node_features,\n",
    "            'continuous_node_features': stacked_continuous_node_features,\n",
    "            'categorical_edge_features': stacked_categorical_edge_features,\n",
    "            'continuous_edge_features': stacked_continuous_edge_features,\n",
    "            'nodes_mask': nodes_mask,\n",
    "            'edge_mask': edge_mask,\n",
    "            'labels': labels}\n",
    "    \n",
    "    if has_metadata:\n",
    "        batch_record['metadata'] = [g['metadata'] for g in batch]\n",
    "\n",
    "    return batch_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder: to embedd categorical variables ( in both node and edge features)\n",
    "from torch.nn import Module\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import Module, ModuleList\n",
    "\n",
    "class Embedder(Module):\n",
    "    def __init__(self, categorical_variables, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.categorical_variables = categorical_variables\n",
    "        embeddings = []\n",
    "        for var in categorical_variables:\n",
    "            num_embeddings = len(var)\n",
    "            if var.has_null_value:\n",
    "            # It's not uncommon to have missing values, we support this assinging a special 0-index which have the zero-vector as its embedding\n",
    "                embedding = Embedding(num_embeddings, embedding_dim, padding_idx=var.get_null_idx())\n",
    "            else:\n",
    "                embedding = Embedding(num_embeddings, embedding_dim)\n",
    "            embeddings.append(embedding)\n",
    "        self.embeddings = ModuleList(embeddings)\n",
    "\n",
    "\n",
    "    def forward(self, categorical_features):\n",
    "        all_embedded_vars = []\n",
    "        for i, embedding in enumerate(self.embeddings):\n",
    "            var_indices = categorical_features[..., i]  \n",
    "            embedded_vars = embedding(var_indices)\n",
    "            all_embedded_vars.append(embedded_vars)\n",
    "\n",
    "        # If you like, you can implement concatenation instead of sum here\n",
    "        stacked_embedded_vars = torch.stack(all_embedded_vars, dim=0)\n",
    "        embedded_vars = torch.sum(stacked_embedded_vars, dim=0)\n",
    "        return embedded_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combiner: to combine categorical and continous data \n",
    "\n",
    "class FeatureCombiner(Module):\n",
    "    def __init__(self, categorical_variables, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.categorical_variables = categorical_variables\n",
    "        self.embedder = Embedder(self.categorical_variables, embedding_dim)\n",
    "        \n",
    "    def forward(self, continuous_features, categorical_features, ):\n",
    "        # We need to be agnostic to whether we have categorical features and continuous features (it's not uncommon to only use one kind)\n",
    "        features = []\n",
    "        if categorical_features is not None:\n",
    "            embedded_features = self.embedder(categorical_features)\n",
    "            features.append(embedded_features)\n",
    "        # The embedded features are now of shape (n_nodes, embedding_dim)\n",
    "        if continuous_features is not None:\n",
    "            features.append(continuous_features)\n",
    "        if len(features) == 0:\n",
    "            raise RuntimeError('No features to combine')\n",
    "        full_features = torch.cat(features, dim=-1)\n",
    "        return full_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph prediction head: this class is used to do graph level predictions at the end \n",
    "\n",
    "class GraphPredictionHeadConfig:\n",
    "  def __init__(self, *, d_model, ffn_dim, pooling_type='sum'):\n",
    "    # Pooling type can be 'sum' or 'mean'\n",
    "    self.d_model = d_model\n",
    "    self.ffn_dim = ffn_dim\n",
    "    self.pooling_type = pooling_type\n",
    "\n",
    "class GraphPredictionHead(Module):\n",
    "    def __init__(self, input_dim, output_dim, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.config = config\n",
    "        self.predictor = Sequential(Linear(self.input_dim, self.config.ffn_dim), \n",
    "                                    ReLU(), \n",
    "                                    Linear(self.config.ffn_dim, self.output_dim))\n",
    "\n",
    "    def forward(self, node_features, node_mask):\n",
    "        if self.config.pooling_type == 'sum':\n",
    "            pooled_nodes = node_features.sum(dim=-2) # node_feat = [B,N,d_n] -> [B,d_n]\n",
    "        elif self.config.pooling_type == 'mean': \n",
    "            node_counts = node_mask.sum(dim=-1)      # node_mask = [B,N] -> [B,1]\n",
    "            summed_feature_vectors = node_features.sum(dim=-2)\n",
    "            pooled_nodes = summed_feature_vectors/node_counts # [B,d_n]/[B,1] ->[B,d_n]\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported pooling type {self.config.pooling_type}')\n",
    "\n",
    "        prediction = self.predictor(pooled_nodes) # [B,d_n] -> [B,d_o]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer layer \n",
    "import math \n",
    "\n",
    "class BasicTransformerConfig:\n",
    "  def __init__(self, *, \n",
    "                d_model: int, \n",
    "                n_layers: int, \n",
    "                ffn_dim: int,\n",
    "                head_dim: int,\n",
    "                layer_normalization: bool = True,\n",
    "                dropout_rate: float = 0.1,\n",
    "                residual_connections: bool=True):\n",
    "    self.d_model = d_model\n",
    "    self.n_layers = n_layers\n",
    "    self.ffn_dim = ffn_dim\n",
    "    self.head_dim = head_dim\n",
    "    self.layer_normalization = layer_normalization\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.residual_connections = residual_connections\n",
    "    \n",
    "class BasicTransformerLayer(Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config \n",
    "        self.input_dim = config.d_model\n",
    "        self.output_dim = config.d_model\n",
    "        self.ffn_dim = config.ffn_dim \n",
    "        self.head_dim = config.head_dim \n",
    "        # Transformers typically don't use mlps, they use linear layers \n",
    "        self.neighbour_transform = Linear(self.input_dim, self.head_dim, bias=False)\n",
    "        self.center_transform = Linear(self.input_dim, self.head_dim, bias=False)\n",
    "        # The transformer uses layer normalization by default\n",
    "        self.attention_norm = LayerNorm(self.input_dim)\n",
    "        self.output_transform = Sequential(Linear(self.input_dim, self.ffn_dim),\n",
    "                                            ReLU(), \n",
    "                                            Linear(self.ffn_dim, self.output_dim))\n",
    "        self.output_norm = LayerNorm(self.output_dim)\n",
    "        self.dropout = Dropout(self.config.dropout_rate)\n",
    "        self.scaling_factor = math.sqrt(self.input_dim)\n",
    "        \n",
    "    def attention_function(self,adjacency_matrix, center_node_features, \n",
    "                            neighbour_node_features, edge_features, node_mask, edge_mask):\n",
    "        # attn_logit: (B,N,d_n) @ (B,d_n,N) -> (B,N,N)\n",
    "        attention_logits = torch.matmul(center_node_features,neighbour_node_features.transpose(-1,-2))/self.scaling_factor\n",
    "        node_mask_2d = node_mask.unsqueeze(dim=-2) * node_mask.unsqueeze(dim=-1) # (B,1,N) * (B,N,1) -> (B,N,N)\n",
    "        fill_mask = (1-node_mask_2d).to(torch.bool) # (B,N,N)\n",
    "        attention_logits.masked_fill_(fill_mask, float('-inf')) # (B,N,N)\n",
    "        attention_matrix = softmax(attention_logits, dim=-1)    # (B,N,N)\n",
    "        attention_matrix = attention_matrix.masked_fill(fill_mask, 0.)\n",
    "        return attention_matrix\n",
    "        \n",
    "    def forward(self,adjacency_matrix, node_features, edge_features, node_mask, edge_mask):\n",
    "        center_node_features = self.center_transform(node_features)       # (B,N,d_h)\n",
    "        neighbour_node_features = self.neighbour_transform(node_features) # (B,N,d_h)\n",
    "        \n",
    "        attention_matrix = self.attention_function(adjacency_matrix, center_node_features,neighbour_node_features, \n",
    "                                                    edge_features, node_mask, edge_mask) # (B,N,N)\n",
    "        # The transformer doesn't transform the node features at this stage\n",
    "        aggregated_neighbourhoods = torch.matmul(attention_matrix,node_features)  # (B,N,N) @ (B,N,d_n) -> (B,N,d_n)\n",
    "        masked_features = aggregated_neighbourhoods * node_mask.unsqueeze(dim=-1) # (B,N,d_n) * (B,N,1) -> (B,N,d_n)\n",
    "        \n",
    "        masked_features = self.dropout(masked_features)\n",
    "        masked_features = self.attention_norm(masked_features)\n",
    "\n",
    "        if self.config.residual_connections:\n",
    "            masked_features = masked_features + node_features  # (B,N,d_n) + (B,N,d_n) -> (B,N,d_n)\n",
    "        \n",
    "        updated_node_features = self.output_transform(masked_features) # (B,N,d_o)\n",
    "        \n",
    "        # Mask again\n",
    "        updated_node_features = updated_node_features * node_mask.unsqueeze(dim=-1)\n",
    "        \n",
    "        # Followed by a dropout and normalization\n",
    "        updated_node_features = self.dropout(updated_node_features)\n",
    "        updated_node_features = self.output_norm(updated_node_features)\n",
    "        \n",
    "        # And the resiudal connection from the input to the output MLP\n",
    "        if self.config.residual_connections:\n",
    "            updated_node_features = updated_node_features + masked_features\n",
    "\n",
    "        return updated_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicTransformerEncoder(torch.nn.Module):\n",
    "    def __init__(self,*,config:BasicTransformerConfig,\n",
    "                continuous_node_variables=None,\n",
    "                categorical_node_variables=None,\n",
    "                continuous_edge_variables=None,\n",
    "                categorical_edge_variables=None,\n",
    "                layer_type:BasicTransformerLayer):\n",
    "        super().__init__()\n",
    "        self.cofig = config\n",
    "        self.layer_type = layer_type\n",
    "        self.continuous_node_variables = continuous_node_variables\n",
    "        self.categorical_node_variables = categorical_node_variables\n",
    "        self.continuous_edge_variables = continuous_edge_variables\n",
    "        self.categorical_edge_variables = categorical_edge_variables\n",
    "        \n",
    "        self.categorical_node_embeddings_dim = config.d_model - len(self.continuous_node_variables)\n",
    "        self.categorical_edge_embeddings_dim = config.d_model - len(self.continuous_edge_variables)\n",
    "        \n",
    "        self.node_featurizer = FeatureCombiner(self.categorical_node_variables, \n",
    "                                            self.categorical_node_embeddings_dim)\n",
    "        self.edge_featurizer = FeatureCombiner(self.categorical_edge_variables, \n",
    "                                            self.categorical_edge_embeddings_dim)\n",
    "        \n",
    "        self.graph_layers = ModuleList([layer_type(config) for l in range(config.n_layers)])\n",
    "        \n",
    "    def forward(self,batch):\n",
    "        \n",
    "        node_mask = batch['node_mask']\n",
    "        batch_size, max_nodes = node_mask.shape\n",
    "        \n",
    "        continuous_node_features = batch['continuous_node_features']\n",
    "        categorical_node_features = batch['categorical_node_features']\n",
    "        node_features = self.node_featurizer(continuous_node_features, categorical_node_features)\n",
    "        masked_node_features = node_features * node_mask*node_mask.unsqueeze(dim=-1)\n",
    "        \n",
    "        edge_mask = batch['edge_mask']\n",
    "        continuous_edge_features = batch['continuous_edge_features']\n",
    "        categorical_edge_features = batch['categorical_edge_features']\n",
    "        edge_features = self.edge_featurizer(continuous_edge_features, categorical_edge_features)\n",
    "        masked_edge_features = edge_features * edge_mask.unsqueeze(dim=-1)\n",
    "        \n",
    "        adjacency_matrix = batch['adjacency_matrices']\n",
    "        memory_state = masked_node_features\n",
    "        for l in self.graph_layers:\n",
    "            memory_state = l(adjacency_matrix,memory_state,masked_edge_features,node_mask,edge_mask)\n",
    "            \n",
    "        return memory_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPredictionNeuralNetwork(Module):\n",
    "    def __init__(self, encoder, prediction_head):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.prediction_head = prediction_head\n",
    "\n",
    "    def forward(self, batch):\n",
    "        encoded_graph = self.encoder(batch)\n",
    "        prediction = self.prediction_head(encoded_graph, batch['nodes_mask'])\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding graph sructure to transfomer \n",
    "\n",
    "class AdjacencyTransformerLayer(BasicTransformerLayer):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.adjacency_weight = Parameter(torch.tensor(1.))\n",
    "    \n",
    "def attention_fucntion(self,adjacency_matrix, center_node_features, \n",
    "                        neighbour_node_features, edge_features, node_mask, edge_mask):\n",
    "    \n",
    "    # transformer dot product (or attention weights)\n",
    "    # (B,N,d_n) @ (B,d_n,N) -> (B,N,N)\n",
    "    dot_product_logits = torch.matmul(center_node_features, \n",
    "                                    neighbour_node_features.transpose(-1, -2))/self.scaling_factor\n",
    "    # graph attention weights\n",
    "    adjacency_logits = self.adjacency_weight*adjacency_matrix\n",
    "    # transformer + graph attenstion weights \n",
    "    attention_logits = dot_product_logits + adjacency_logits\n",
    "    \n",
    "    nodemask_2d = node_mask.unsqueeze(dim=-2) * node_mask.unsqueeze(dim=-1)\n",
    "    fill_mask = (1 - nodemask_2d).to(torch.bool)\n",
    "    attention_logits.masked_fill_(fill_mask, float('-inf'))\n",
    "    attention_matrix = softmax(attention_logits, dim=-1)\n",
    "    \n",
    "    attention_matrix = attention_matrix.masked_fill(fill_mask, 0.)\n",
    "    return attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge features in attention: here edge features (in addition to node features) are used for the attention weights \n",
    "\n",
    "class EdgeAttributesAttentionTransformerLayer(BasicTransformerLayer):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "    # We're going to sum our center and neighbour vectors to the edge feature\n",
    "    # vector, so have to be mindful of the dimensionality\n",
    "    self.center_transform = Linear(self.input_dim, self.input_dim)\n",
    "    self.neighbour_transform = Linear(self.input_dim, self.input_dim)\n",
    "    self.attention_score_function = Sequential(Linear(self.input_dim, self.config.ffn_dim),ReLU(), \n",
    "                                                Linear(self.config.ffn_dim, 1))\n",
    "    \n",
    "def attention_fucntion(self,adjacency_matrix,center_node_features,neighbour_node_features,\n",
    "                        edge_features,node_mask,edge_mask):\n",
    "    attention_score_input = edge_features + center_node_features.unsqueeze(dim=-2) # (B,N,N,d_e) + (B,N,1,d_n) -> (B,N,N,d_0)\n",
    "    attention_score_input = attention_score_input + neighbour_node_features.unsqueeze(dim=-3) # (B,N,N,d_0) + (B,1,N,d_n)->(B,N,N,d_0)\n",
    "    attention_logits = self.attention_score_function(attention_score_input).sum(dim=-1) # (B,N,N,d_0) @ (B,N,d_0,N) -> (B,N,N,N)->(B,N,N)\n",
    "    # nm : (B,N)->(B,1,N)*(B,N,1) -> (B,N,N)\n",
    "    nodemask_2d = node_mask.unsqueeze(dim=-2) * node_mask.unsqueeze(dim=-1)\n",
    "    fill_mask = (1 - nodemask_2d).to(torch.bool)\n",
    "    attention_logits.masked_fill_(fill_mask, float('-inf')) # (B,N,N)\n",
    "    attention_matrix = softmax(attention_logits, dim=-1)    # (B,N,N)\n",
    "    attention_matrix = attention_matrix.masked_fill(fill_mask, 0.)\n",
    "    return attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EdgeAttributesTransformerLayer(EdgeAttributesAttentionTransformerLayer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, adjacency_matrix, node_features, edge_features, node_mask, edge_mask):\n",
    "        center_node_features = self.center_transform(node_features)\n",
    "        neighbour_node_features = self.center_transform(node_features)\n",
    "        attention_matrix = self.attention_function(adjacency_matrix, center_node_features,neighbour_node_features, \n",
    "                                                    edge_features,node_mask, edge_mask)\n",
    "        \n",
    "        # here we use combined features (edge + center_node + neighbour_node) in the transformer \n",
    "        context_dependent_features = edge_features + center_node_features.unsqueeze(dim=-2) # (B,N,N,d_e) + (B,N,1,d_n)-> (B,N,N,d_n), assume d_n =d_e\n",
    "        context_dependent_features = context_dependent_features + neighbour_node_features.unsqueeze(dim=-3) # (B,N,N,d_n) + (B,1,N,d_n) -> (B,N,N,d_n)\n",
    "        attended_features = context_dependent_features * attention_matrix.unsqueeze(dim=-1) # (B,N,N,d_n) * (B,N,N,1)-> (B,N,N,d_n)\n",
    "        aggregated_neighbourhoods = attended_features.sum(dim=-2)  # (B,N,N,d_n) -> (B,N,d_n)\n",
    "        masked_features = aggregated_neighbourhoods * node_mask.unsqueeze(dim=-1) # (B,N,d_n) * (B,N,1) -> (B,N,d_n)\n",
    "        \n",
    "        masked_features = self.dropout(masked_features)\n",
    "        masked_features = self.attention_norm(masked_features)\n",
    "        \n",
    "        if self.config.residual_connections:\n",
    "            masked_features = masked_features + node_features\n",
    "            \n",
    "        updated_node_features = self.output_transform(masked_features)\n",
    "        updated_node_features = updated_node_features * node_mask.unsqueeze(dim=-1)\n",
    "        \n",
    "        if self.config.residual_connections:\n",
    "            updated_node_features = updated_node_features + masked_features\n",
    "\n",
    "        return updated_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
