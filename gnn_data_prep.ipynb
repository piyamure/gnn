{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/caffeine.png\" alt=\"drawing\" width=\"500\" align=\"left\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a graph \n",
    "\n",
    "* You need to define node features and Edge features for the graph \n",
    "\n",
    "* The node features has shape of: ~ (N, node_features)\n",
    "\n",
    "* And the edge features dictionary has shape of: ~ (N, N, edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usally we create this for all the molecules  in the problem (here we are showing for one molecule)\n",
    "# So we need to update the ATOM_TYPE and BOND_TYPE lists based on the all elements and all type of bonds we are going to work on \n",
    "# also here we are considering one node feature (atom) and one edge feature (bond type), but in general we have more than one\n",
    "\n",
    "ATOM_TYPES = {'C': 0, 'N': 1, 'O': 2} # nodes encoding \n",
    "BOND_TYPES = {'S': 0, 'D': 1, 'A': 2} # edges encoding \n",
    "\n",
    "# caffeine nodes \n",
    "sym_caffeine_nodes = {1: {'atom_type': 'C'},\n",
    "                    2: {'atom_type': 'N'},\n",
    "                    3: {'atom_type': 'C'},\n",
    "                    4: {'atom_type': 'O'},\n",
    "                    5: {'atom_type': 'C'},\n",
    "                    6: {'atom_type': 'N'},\n",
    "                    7: {'atom_type': 'C'},\n",
    "                    8: {'atom_type': 'C'},\n",
    "                    9: {'atom_type': 'N'},\n",
    "                    10: {'atom_type': 'C'},\n",
    "                    11: {'atom_type': 'N'},\n",
    "                    12: {'atom_type': 'C'},\n",
    "                    13: {'atom_type': 'C'},\n",
    "                    14: {'atom_type': 'O'}}\n",
    "\n",
    "# caffeine edges \n",
    "sym_caffeine_edges = {frozenset({1,2}): {'bond_type': 'S'},\n",
    "                    frozenset({2,3}): {'bond_type': 'S'},\n",
    "                    frozenset({2,13}): {'bond_type': 'S'},\n",
    "                    frozenset({3,4}): {'bond_type': 'D'},\n",
    "                    frozenset({3,5}): {'bond_type': 'S'},\n",
    "                    frozenset({5,6}): {'bond_type': 'A'},\n",
    "                    frozenset({5,10}): {'bond_type': 'A'},\n",
    "                    frozenset({6,7}): {'bond_type': 'S'},\n",
    "                    frozenset({6,8}): {'bond_type': 'A'},\n",
    "                    frozenset({8,9}): {'bond_type': 'A'},\n",
    "                    frozenset({9,10}): {'bond_type': 'A'},\n",
    "                    frozenset({10,11}): {'bond_type': 'S'},\n",
    "                    frozenset({11,12}): {'bond_type': 'S'},\n",
    "                    frozenset({11,13}): {'bond_type': 'S'},\n",
    "                    frozenset({13,14}): {'bond_type': 'D'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node features \n",
    "\n",
    "1. We need to first encode the categorical node features into integers \n",
    "2. Then we need to create embeddings for (each) encoded integers\n",
    "3. Finally the numerical node features will be stacked to have shape of: (N, node_feat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'atom_type': 0},\n",
       " 2: {'atom_type': 1},\n",
       " 3: {'atom_type': 0},\n",
       " 4: {'atom_type': 2},\n",
       " 5: {'atom_type': 0},\n",
       " 6: {'atom_type': 1},\n",
       " 7: {'atom_type': 0},\n",
       " 8: {'atom_type': 0},\n",
       " 9: {'atom_type': 1},\n",
       " 10: {'atom_type': 0},\n",
       " 11: {'atom_type': 1},\n",
       " 12: {'atom_type': 0},\n",
       " 13: {'atom_type': 0},\n",
       " 14: {'atom_type': 2}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode node attributes \n",
    "enc_caffeine_nodes = {}\n",
    "for node_idx, node_attributes in sym_caffeine_nodes.items():\n",
    "    sym_atom_type = node_attributes['atom_type']\n",
    "    encoded_atom_type = ATOM_TYPES[sym_atom_type]\n",
    "    enc_caffeine_nodes[node_idx] = {'atom_type': encoded_atom_type}\n",
    "\n",
    "enc_caffeine_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1, 2}): {'bond_type': 0},\n",
       " frozenset({2, 3}): {'bond_type': 0},\n",
       " frozenset({2, 13}): {'bond_type': 0},\n",
       " frozenset({3, 4}): {'bond_type': 1},\n",
       " frozenset({3, 5}): {'bond_type': 0},\n",
       " frozenset({5, 6}): {'bond_type': 2},\n",
       " frozenset({5, 10}): {'bond_type': 2},\n",
       " frozenset({6, 7}): {'bond_type': 0},\n",
       " frozenset({6, 8}): {'bond_type': 2},\n",
       " frozenset({8, 9}): {'bond_type': 2},\n",
       " frozenset({9, 10}): {'bond_type': 2},\n",
       " frozenset({10, 11}): {'bond_type': 0},\n",
       " frozenset({11, 12}): {'bond_type': 0},\n",
       " frozenset({11, 13}): {'bond_type': 0},\n",
       " frozenset({13, 14}): {'bond_type': 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode edge attributes \n",
    "enc_caffeine_edges = {}\n",
    "for edge, edge_attributes in sym_caffeine_edges.items():\n",
    "    sym_bond_type = edge_attributes['bond_type']\n",
    "    encoded_bond_type = BOND_TYPES[sym_bond_type]\n",
    "    enc_caffeine_edges[edge] = {'bond_type': encoded_bond_type}\n",
    "    \n",
    "enc_caffeine_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "          1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "          3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "         -2.6490e-01],\n",
       "        [ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
       "         -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
       "          3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
       "         -9.2283e-04],\n",
       "        [ 3.8197e-02,  4.1376e-02, -3.5007e-01, -1.0524e-01, -3.2507e-01,\n",
       "          1.5805e+00, -3.6525e-01,  5.5840e-01, -6.1863e-01, -1.0399e+00,\n",
       "          1.0893e+00,  1.8452e+00,  3.2104e-01, -1.3400e+00, -2.3157e-02,\n",
       "         -1.5424e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node embeddings (for catergorical data)\n",
    "num_embeddings = len(ATOM_TYPES)\n",
    "embedding_dim = 16  # This is a hyper parameter\n",
    "\n",
    "# one embedding vector for one atom type (i.e. if the atom is same, then the embedding vector will be same )\n",
    "ATOM_TYPE_EMBEDDINGS = torch.randn((num_embeddings, embedding_dim))\n",
    "ATOM_TYPE_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'atom_type': tensor([-2.9771,  0.7249, -1.2857,  0.9568,  0.7551,  1.9142, -0.1548, -1.0595,\n",
      "         1.8215,  1.8802,  0.0397,  0.3785,  1.0095, -1.7395,  0.2844, -0.2649])}\n",
      "2 {'atom_type': tensor([ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
      "        -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
      "         3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
      "        -9.2283e-04])}\n",
      "3 {'atom_type': tensor([-2.9771,  0.7249, -1.2857,  0.9568,  0.7551,  1.9142, -0.1548, -1.0595,\n",
      "         1.8215,  1.8802,  0.0397,  0.3785,  1.0095, -1.7395,  0.2844, -0.2649])}\n"
     ]
    }
   ],
   "source": [
    "# embedded caffeine nodes \n",
    "embedded_caffeine_nodes = {}\n",
    "for node_idx, encoded_node_features in enc_caffeine_nodes.items():\n",
    "    encoded_atom_type = encoded_node_features['atom_type']\n",
    "    embedded_atom_type = ATOM_TYPE_EMBEDDINGS[encoded_atom_type]  \n",
    "    embedded_node_features = {'atom_type': embedded_atom_type}\n",
    "    embedded_caffeine_nodes[node_idx] = embedded_node_features\n",
    "\n",
    "# print first 3 \n",
    "i=0\n",
    "for idx,embedded_node_feats in embedded_caffeine_nodes.items():\n",
    "    if i<3:\n",
    "        print(idx,embedded_node_feats)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to create tensors (here we are stacking node fatures for each node)\n",
    "# Please read slide #1 in the GNN powerpoint \n",
    "caffeine_node_features_stack = dict()\n",
    "for node_idx,embedded_features in sorted(embedded_caffeine_nodes.items()):\n",
    "    for varibale_name, embedding in embedded_features.items():\n",
    "        if varibale_name not in caffeine_node_features_stack:\n",
    "            caffeine_node_features_stack[varibale_name] = []\n",
    "        caffeine_node_features_stack[varibale_name].append(embedding)\n",
    "        \n",
    "stacked_node_features = dict()\n",
    "for variable_name,stack in caffeine_node_features_stack.items():\n",
    "    feature_tensor = torch.stack(stack)\n",
    "    stacked_node_features[variable_name] = feature_tensor\n",
    "\n",
    "stacked_node_features['atom_type'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_type': [0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's combine the steps involving encoding and embedding (seperatly)\n",
    "\n",
    "# STEP 1: ENCODING \n",
    "enc_caffeine_nodes_stack = {'atom_type': []}\n",
    "for node_idx, node_attributes in sym_caffeine_nodes.items():\n",
    "    sym_atom_type = node_attributes['atom_type']\n",
    "    encoded_atom_type = ATOM_TYPES[sym_atom_type]\n",
    "    enc_caffeine_nodes_stack['atom_type'].append(encoded_atom_type)\n",
    "enc_caffeine_nodes_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_type': tensor([[-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
       "          -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
       "           3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
       "          -9.2283e-04],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 3.8197e-02,  4.1376e-02, -3.5007e-01, -1.0524e-01, -3.2507e-01,\n",
       "           1.5805e+00, -3.6525e-01,  5.5840e-01, -6.1863e-01, -1.0399e+00,\n",
       "           1.0893e+00,  1.8452e+00,  3.2104e-01, -1.3400e+00, -2.3157e-02,\n",
       "          -1.5424e-01],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
       "          -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
       "           3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
       "          -9.2283e-04],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
       "          -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
       "           3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
       "          -9.2283e-04],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 2.0475e+00,  7.0039e-01,  1.3285e+00, -1.5199e+00, -3.7156e-01,\n",
       "          -1.0798e+00, -3.3433e-01, -1.7535e+00, -1.7819e+00, -9.9619e-01,\n",
       "           3.1049e-01, -8.2550e-01,  2.3600e-01,  8.9366e-01, -1.5740e-01,\n",
       "          -9.2283e-04],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [-2.9771e+00,  7.2485e-01, -1.2857e+00,  9.5681e-01,  7.5506e-01,\n",
       "           1.9142e+00, -1.5479e-01, -1.0595e+00,  1.8215e+00,  1.8802e+00,\n",
       "           3.9737e-02,  3.7848e-01,  1.0095e+00, -1.7395e+00,  2.8441e-01,\n",
       "          -2.6490e-01],\n",
       "         [ 3.8197e-02,  4.1376e-02, -3.5007e-01, -1.0524e-01, -3.2507e-01,\n",
       "           1.5805e+00, -3.6525e-01,  5.5840e-01, -6.1863e-01, -1.0399e+00,\n",
       "           1.0893e+00,  1.8452e+00,  3.2104e-01, -1.3400e+00, -2.3157e-02,\n",
       "          -1.5424e-01]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP2: EMBEDDING \n",
    "emb_caffeine_nodes_stack = {}\n",
    "for variable_name, encoded_stack in enc_caffeine_nodes_stack.items():\n",
    "    enc_tensor = torch.tensor(encoded_stack, dtype=torch.long)\n",
    "    emb_tensor = ATOM_TYPE_EMBEDDINGS[enc_tensor] \n",
    "    emb_caffeine_nodes_stack[variable_name] = emb_tensor\n",
    "emb_caffeine_nodes_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4365, -0.3588, -0.5799, -0.3170, -0.6660, -0.4050, -0.7571, -1.0767,\n",
       "          0.2133, -0.1208,  0.2787,  0.9280,  1.0981, -0.7721, -0.6524,  1.7539],\n",
       "        [ 0.5037,  0.7694,  0.2166, -0.2285, -0.5482,  0.5331,  1.2060,  0.2541,\n",
       "          0.2591,  1.3566,  2.0879, -1.1296, -1.7258, -0.8251, -0.3775, -0.1348],\n",
       "        [-0.2887, -0.1910, -0.1301,  0.5817, -0.1459,  1.9326,  0.8524, -0.0810,\n",
       "          1.8143, -0.6092, -0.2389, -1.7950, -0.1198, -0.8289,  0.4891, -1.9112]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bond type embedding \n",
    "num_embeddings = len(BOND_TYPES)\n",
    "embedding_dim = 16  # This is a hyper parameter, you can set it to whatever value you like (though 1 will work poorly)\n",
    "BOND_TYPE_EMBEDDINGS = torch.randn((num_embeddings, embedding_dim))\n",
    "BOND_TYPE_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emplty (filled with zeros) caffine edge feature tensor \n",
    "caffeine_nodes = sym_caffeine_nodes.keys()\n",
    "n_nodes = len(caffeine_nodes)\n",
    "caffeine_nodes_indices = {node_idx: i for i, node_idx in enumerate(sorted(caffeine_nodes))} # to get indx -> int \n",
    "caffeine_edge_features_tensor = torch.zeros((n_nodes, n_nodes, embedding_dim), dtype=BOND_TYPE_EMBEDDINGS.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({1, 2}) {'bond_type': tensor([-2.9771,  0.7249, -1.2857,  0.9568,  0.7551,  1.9142, -0.1548, -1.0595,\n",
      "         1.8215,  1.8802,  0.0397,  0.3785,  1.0095, -1.7395,  0.2844, -0.2649])}\n",
      "frozenset({2, 3}) {'bond_type': tensor([-2.9771,  0.7249, -1.2857,  0.9568,  0.7551,  1.9142, -0.1548, -1.0595,\n",
      "         1.8215,  1.8802,  0.0397,  0.3785,  1.0095, -1.7395,  0.2844, -0.2649])}\n",
      "frozenset({2, 13}) {'bond_type': tensor([-2.9771,  0.7249, -1.2857,  0.9568,  0.7551,  1.9142, -0.1548, -1.0595,\n",
      "         1.8215,  1.8802,  0.0397,  0.3785,  1.0095, -1.7395,  0.2844, -0.2649])}\n"
     ]
    }
   ],
   "source": [
    "# embedded caffeine edges \n",
    "embedded_caffeine_edges = {}\n",
    "\n",
    "for edge_idx, encoded_edge_features in enc_caffeine_edges.items():\n",
    "    encoded_bond_type = encoded_edge_features['bond_type']\n",
    "    embedded_bond_type = ATOM_TYPE_EMBEDDINGS[encoded_bond_type]\n",
    "    embedded_bond_features = {'bond_type':embedded_bond_type}\n",
    "    embedded_caffeine_edges[edge_idx] = embedded_bond_features\n",
    "    \n",
    "# print first 3  \n",
    "i=0\n",
    "for idx,embedded_edge_feats in embedded_caffeine_edges.items():\n",
    "    if i<3:\n",
    "        print(idx,embedded_edge_feats)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (node_u,node_v),features in embedded_caffeine_edges.items():\n",
    "    node_u_idx = caffeine_nodes_indices[node_u]\n",
    "    node_v_idx = caffeine_nodes_indices[node_v]\n",
    "    caffeine_edge_features_tensor[node_u_idx,node_v_idx] = features['bond_type']\n",
    "    \n",
    "# has shape of : (N,N,d_edge_feat)\n",
    "caffeine_edge_features_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Categorical and continuos  variable class \n",
    "\n",
    "* This makes easy to handle categorical data and continuous data effectively \n",
    "* For example if we want to define the \"NULL\" category this makes it easier, we don't need to handle it separately every time when we define categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for continous data \n",
    "class ContinuousVariable:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for categorical data \n",
    "\n",
    "class CategoricalVariable:\n",
    "    def __init__(self, name, values, add_null_value=True):\n",
    "        self.name = name\n",
    "        self.has_null_value = add_null_value\n",
    "        if self.has_null_value:\n",
    "            self.null_value = None\n",
    "            values = (None,) + tuple(values)\n",
    "        self.values = tuple(values)\n",
    "        self.value_to_idx_mapping = {v: i for i, v in enumerate(values)}\n",
    "        self.inv_value_to_idx_mapping = {i: v for v, i in\n",
    "                                            self.value_to_idx_mapping.items()}\n",
    "\n",
    "        if self.has_null_value:\n",
    "            self.null_value_idx = self.value_to_idx_mapping[self.null_value]\n",
    "\n",
    "    def get_null_idx(self):\n",
    "        if self.has_null_value:\n",
    "            return self.null_value_idx\n",
    "        else:\n",
    "            raise RuntimeError(f\"Categorical variable {self.name} has no null value\")\n",
    "\n",
    "    def value_to_idx(self, value):\n",
    "        return self.value_to_idx_mapping[value]\n",
    "\n",
    "    def idx_to_value(self, idx):\n",
    "        return self.inv_value_to_idx_mapping[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.values == other.values\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding multiple node and edge attributes\n",
    "\n",
    "* So far we encoded one node feature (atom type) and one edge feature (bond type)\n",
    "\n",
    "* Let's try to generalize this for multiple node features (ex. 'atom_type', 'is_aromatic', 'num_hydrogen' and etc) and multiple edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node features (here we have 4 features)\n",
    "ATOM_TYPE_VARIABLE = CategoricalVariable('atom_type', ['C', 'N', 'O'])\n",
    "ATOM_IS_AROMATIC_VARIABLE = CategoricalVariable('is_aromatic', [True, False])\n",
    "ATOM_HYDROGENS_VARIABLE = ContinuousVariable('num_hydrogens')\n",
    "ATOM_VARIABLES = [ATOM_TYPE_VARIABLE, ATOM_IS_AROMATIC_VARIABLE, ATOM_HYDROGENS_VARIABLE]\n",
    "\n",
    "# let's put node features in the node dictionary \n",
    "caffeine_nodes = {1: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                2: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                3: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                4: {ATOM_TYPE_VARIABLE: 'O', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                5: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                6: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                7: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                8: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 1},\n",
    "                9: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                10: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: True, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                11: {ATOM_TYPE_VARIABLE: 'N', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                12: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 3},\n",
    "                13: {ATOM_TYPE_VARIABLE: 'C', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0},\n",
    "                14: {ATOM_TYPE_VARIABLE: 'O', ATOM_IS_AROMATIC_VARIABLE: False, ATOM_HYDROGENS_VARIABLE: 0}}\n",
    "\n",
    "# edge features (we have 3 here)\n",
    "BOND_TYPES_VARIABLE = CategoricalVariable('bond_type', ('S', 'D', 'A'))\n",
    "BOND_IS_AROMATIC_VARIABLE = CategoricalVariable('is_aromatic', (True, False))\n",
    "BOND_VARIABLES = [BOND_TYPES_VARIABLE, BOND_IS_AROMATIC_VARIABLE]\n",
    "\n",
    "# let's put the edge features in feature dictionary \n",
    "caffeine_edges = {frozenset({1,2}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({2,3}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({2,13}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({3,4}): {BOND_TYPES_VARIABLE: 'D', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({3,5}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({5,6}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({5,10}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({6,7}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({6,8}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({8,9}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({9,10}): {BOND_TYPES_VARIABLE: 'A', BOND_IS_AROMATIC_VARIABLE: True},\n",
    "                frozenset({10,11}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({11,12}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({11,13}): {BOND_TYPES_VARIABLE: 'S', BOND_IS_AROMATIC_VARIABLE: False},\n",
    "                frozenset({13,14}): {BOND_TYPES_VARIABLE: 'D', BOND_IS_AROMATIC_VARIABLE: False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom and bond variables (categorical and continous)\n",
    "\n",
    "CATEGORICAL_ATOM_VARIABLES = [var for var in ATOM_VARIABLES if isinstance(var, CategoricalVariable)]\n",
    "CONTINUOUS_ATOM_VARIABLES = [var for var in ATOM_VARIABLES if isinstance(var, ContinuousVariable)]\n",
    "\n",
    "CATEGORICAL_BOND_VARIABLES = [var for var in BOND_VARIABLES if isinstance(var, CategoricalVariable)]\n",
    "CONTINUOUS_BOND_VARIABLES = [var for var in BOND_VARIABLES if isinstance(var, ContinuousVariable)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per variable embedding \n",
    "\n",
    "from torch.nn import Embedding\n",
    "\n",
    "def make_embedding(var, embedding_dim):\n",
    "    num_embeddings = len(var)\n",
    "    if var.has_null_value:\n",
    "        pad_idx = var.get_null_idx()\n",
    "        embedding = Embedding(num_embeddings, embedding_dim, padding_idx=pad_idx)\n",
    "    else:\n",
    "        embedding = Embedding(num_embeddings, embedding_dim)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding for catergorical variables \n",
    "\n",
    "embedding_dim = 16 # This is a hyper parameter\n",
    "\n",
    "ATOM_EMBEDDINGS = { var:make_embedding(var, embedding_dim) for var in CATEGORICAL_ATOM_VARIABLES }\n",
    "BOND_EMBEDDINGS = { var: make_embedding(var, embedding_dim) for var in CATEGORICAL_BOND_VARIABLES }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{atom_type: Embedding(4, 16, padding_idx=0),\n",
       " is_aromatic: Embedding(3, 16, padding_idx=0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATOM_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({atom_type: [1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 2, 1, 1, 3],\n",
       "  is_aromatic: [2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2]},\n",
       " {num_hydrogens: [3, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 3, 0, 0]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking features for multiple variables \n",
    "\n",
    "stacked_encoded_categorical_node_features = {var: [] for var in CATEGORICAL_ATOM_VARIABLES}\n",
    "stacked_continuous_node_features = {var: [] for var in CONTINUOUS_ATOM_VARIABLES}\n",
    "\n",
    "for node_idx, features in sorted(caffeine_nodes.items()):\n",
    "  for var in CATEGORICAL_ATOM_VARIABLES:\n",
    "    symbolic_value = features[var]\n",
    "    encoded_value = var.value_to_idx(symbolic_value)\n",
    "    stacked_encoded_categorical_node_features[var].append(encoded_value)\n",
    "  for var in CONTINUOUS_ATOM_VARIABLES:\n",
    "    value = features[var]\n",
    "    stacked_continuous_node_features[var].append(value)\n",
    "\n",
    "stacked_encoded_categorical_node_features, stacked_continuous_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{bond_type: tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 3, 0, 1, 3, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]]),\n",
       " is_aromatic: tensor([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
       "         [0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "         [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = len(caffeine_nodes)\n",
    "caffeine_nodes_indices = {node_idx: i for i, node_idx in enumerate(sorted(caffeine_nodes.keys()))}\n",
    "\n",
    "# stacked catogorical edge features encoding \n",
    "stacked_encoded_categorical_edge_features = {}\n",
    "\n",
    "for var in CATEGORICAL_BOND_VARIABLES:\n",
    "    pairwise_tensor = torch.zeros((n_nodes,n_nodes),dtype=torch.long)\n",
    "    for (node_u,node_v), features in caffeine_edges.items():\n",
    "         node_u_idx = caffeine_nodes_indices[node_u]\n",
    "         node_v_idx = caffeine_nodes_indices[node_v]\n",
    "         symbolic_value = features[var]\n",
    "         encoded_value = var.value_to_idx(symbolic_value)\n",
    "         pairwise_tensor[node_u_idx,node_v_idx] = encoded_value\n",
    "         pairwise_tensor[node_v_idx,node_u_idx] = encoded_value\n",
    "         \n",
    "    stacked_encoded_categorical_edge_features[var] = pairwise_tensor\n",
    "    \n",
    "stacked_encoded_categorical_edge_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacked continous edge feature \n",
    "stacked_continuous_edge_features = {}\n",
    "\n",
    "for var in CONTINUOUS_BOND_VARIABLES:\n",
    "    pairwise_tensor = torch.zeros((n_nodes,n_nodes),dtype=torch.float32)\n",
    "    for (node_u,node_v), features in caffeine_edges.items():\n",
    "        node_u_idx = caffeine_nodes_indices[node_u]\n",
    "        node_v_idx = caffeine_nodes_indices[node_v]\n",
    "        value = features[var]\n",
    "        pairwise_tensor[node_u_idx, node_v_idx] = value\n",
    "        pairwise_tensor[node_v_idx, node_u_idx] = value\n",
    "    stacked_encoded_categorical_edge_features[var] = pairwise_tensor\n",
    "    \n",
    "stacked_continuous_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets embed the stacked encoded bond features \n",
    "\n",
    "embedded_node_features = dict()\n",
    "for var, encoded_features in stacked_encoded_categorical_node_features.items():\n",
    "  tensor_features = torch.tensor(encoded_features, dtype=torch.long)\n",
    "  embedding = ATOM_EMBEDDINGS[var]\n",
    "  embedded_features = embedding(tensor_features)\n",
    "  embedded_node_features[var] = embedded_features\n",
    "\n",
    "# for the continous variables we don't need embedding \n",
    "continuous_node_features = dict()\n",
    "for var, features in stacked_continuous_node_features.items():\n",
    "    continuous_node_features[var] = torch.tensor(features, dtype=torch.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28156/1647392056.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_features = torch.tensor(encoded_features, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# embed the steacked encoded edge features \n",
    "embedded_edge_features = dict()\n",
    "for var, encoded_features in stacked_encoded_categorical_edge_features.items():\n",
    "    tensor_features = torch.tensor(encoded_features, dtype=torch.long)\n",
    "    embedding = BOND_EMBEDDINGS[var]\n",
    "    embedded_features = embedding(tensor_features)\n",
    "    embedded_edge_features[var] = embedded_features\n",
    "\n",
    "# for the continous edge features no embedding is needed \n",
    "continuous_edge_features = dict()\n",
    "for var, features in stacked_continuous_edge_features.items():\n",
    "    continuous_edge_features[var] = torch.tensor(features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's examine the shapes of encoded (and embedded if categorical) bond and edge features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_name = \"atom_type\" and shape = torch.Size([14, 16])\n",
      "var_name = \"is_aromatic\" and shape = torch.Size([14, 16])\n"
     ]
    }
   ],
   "source": [
    "# categorical node features \n",
    "for name,value in embedded_node_features.items():\n",
    "    print(f'var_name = \"{name}\" and shape = {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_name = \"num_hydrogens\" and shape = torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "# continuous node features \n",
    "\n",
    "for name,value in continuous_node_features.items():\n",
    "    print(f'var_name = \"{name}\" and shape = {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_name = \"bond_type\" and shape = torch.Size([14, 14, 16])\n",
      "var_name = \"is_aromatic\" and shape = torch.Size([14, 14, 16])\n"
     ]
    }
   ],
   "source": [
    "# categorical edge features \n",
    "for name,value in embedded_edge_features.items():\n",
    "    print(f'var_name = \"{name}\" and shape = {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_name = \"num_hydrogens\" and shape = torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "# continuous edge features \n",
    "for name,value in continuous_node_features.items():\n",
    "    print(f'var_name = \"{name}\" and shape = {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 17])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine embedded and continous node features\n",
    "\n",
    "# stack along 0 dim and sum along 0 dim -> sum the node embeddings \n",
    "stacked_node_embedding = torch.stack(tuple(embedded_node_features.values()))  \n",
    "aggregated_node_embeddings = torch.sum(stacked_node_embedding,dim=0)          \n",
    "\n",
    "# stack cts features along last axis -> concatanting \n",
    "continuous_node_features_stacked = torch.stack(tuple(continuous_node_features.values()), dim=-1) \n",
    "\n",
    "# concatante agg. node embeddings with stacked cts features to form node feature tensor \n",
    "node_features = torch.concat([aggregated_node_embeddings, continuous_node_features_stacked], dim=-1)\n",
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14, 16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine embedded and continous node features \n",
    "\n",
    "# stack edge embeddings and aggregate (for. ex sum)\n",
    "stacked_edge_embeddings = torch.stack(tuple(embedded_edge_features.values()))\n",
    "aggregated_edge_embeddings = torch.sum(stacked_edge_embeddings, dim=0)\n",
    "\n",
    "# stack cts variable \n",
    "# continuous_edge_features_stacked = torch.stack(tuple(continuous_edge_features.values()), dim=-1) \n",
    "# edge_features = torch.concat([aggregated_edge_embeddings,continuous_edge_features_stacked])\n",
    "\n",
    "# since we don't have cts edge features \n",
    "edge_features = aggregated_edge_embeddings\n",
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
